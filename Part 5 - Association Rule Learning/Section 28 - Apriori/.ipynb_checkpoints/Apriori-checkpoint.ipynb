{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori for Associative Rule Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index \n",
    "- [Equation and Method](#equation)\n",
    "- [Pre processing](#preprocessing)\n",
    "- [Building the model](#building)\n",
    "- [Result](#result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing some basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='equation'></a>\n",
    "### Equation and Method\n",
    "\n",
    "Apriori is a method for associative rule learning where we estimate the associativity of items by using some formulas just like in bayes theorem. The formula for the apriori algorithm are defined by 3 terms.\n",
    "\n",
    "- $Support$\n",
    "- $Confidence$\n",
    "- $Lift$\n",
    "\n",
    "###### Support ($M$)\n",
    "Support is the percentage of our interested item with respect to the total number of items.\n",
    "\n",
    "### $support = \\frac{total(M)}{total number of items}$\n",
    "Support is generally specified for M2 according to our current formula terminology.\n",
    "\n",
    "##### Confidence ($M1$ ---> $M2$)\n",
    "Confidence is the percentage of items having both $M1$ & $M2$ with respect to items having $M1$\n",
    "\n",
    "### $confidence = \\frac{total(M1--->M2)}{total(M1)}$\n",
    "\n",
    "###### Lift (lift($M1$ ---> $M2$))\n",
    "Lift is the measure of how our Confidnece improves, with respect to the support. I.e, having high support and confidence will result in a value that is low, meaning that there is no specific associativity between them when in fact the truth is that the associativity is not for that particular item but for everything commonly. However, if we have the confidence value high and the support is low. That results in a higher Lift. This suggests us that there is a high associativity with the two items\n",
    "\n",
    "### $lift = \\frac{confidence(M1-->M2)}{support(M2)}$\n",
    "\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. Set a minimum support and confidence\n",
    "2. Take all the subsets in transactions having higher support than minimum support\n",
    "3. Take all the rules of these subsets having higher confidence than minimum confidence.\n",
    "4. Sort the rules by decreasing lift.\n",
    "\n",
    "This method is quite effective but it is not very efficient.\n",
    "\n",
    "The algorithm implementation in detail is given,\n",
    "\n",
    "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/8eed75c18217fe2f9b15f266c40b369ce038164d' style=\"margin:0px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='preprocessing'></a>\n",
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## importing the libraries for simple linear regression.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a06301b30125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Social_Network_Ads.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "datset = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = datset.iloc[:, 2:4].values\n",
    "y = datset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='building'></a>\n",
    "### Building the model.\n",
    "Training the model using Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='result'></a>\n",
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_regions(x, y, title):\n",
    "    X_set, y_set = x, y\n",
    "    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "                 alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "    plt.xlim(X1.min(), X1.max())\n",
    "    plt.ylim(X2.min(), X2.max())\n",
    "    for i, j in enumerate(np.unique(y_set)):\n",
    "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                    c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Estimated Salary')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_regions(x_train, y_train, 'Classifier (Test set)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

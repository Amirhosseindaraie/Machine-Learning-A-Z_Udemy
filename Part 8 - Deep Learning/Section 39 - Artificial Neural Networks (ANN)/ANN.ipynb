{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index \n",
    "- [Equation and Method](#equation)\n",
    "- [Pre processing](#preprocessing)\n",
    "- [Building the model](#building)\n",
    "- [Result](#result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing some basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='equation'></a>\n",
    "### Equation and Method\n",
    "\n",
    "##### Neuron\n",
    "The basic idea behind deep learning is to form neurons just like the brain cells, They will be highly interconnected and each connection will have a weight by which they matter. This is how a neural network functions. In deeplearning, we code this artificial neural network for and devise ways by which the training takes place and so on.\n",
    "\n",
    "##### Activation function\n",
    "The input at a neuron will be the sum of all the product of the input and the weights associated with the input connection. This input is then given to an activation function associated with that particular neuron. This activation function predicts the output/result of that particualar neuron. There are different activation functions which are commonly used. They are:\n",
    "- Step Function\n",
    "- Sigmoid Function\n",
    "- Rectified Linear Function\n",
    "- Softmax\n",
    "\n",
    "##### Learning\n",
    "After the inputs are propogated along the neural network, we need to compare it to the original required output vs the predicted one and then update the weights in order to make it close to the original desired output. For that we use differnt methods to predict the direction we want to move. Basically, we use a loss function (eg: OLS) and then we change the inputs in the desired direction, i.e where we want to reduce the error. One such method is the gradient descent.\n",
    "\n",
    "##### Gradient descent\n",
    "In gradient descent, what happens is that we differentiate the point which we obtained to find the slope at that particular point. I.e to find the direction of error and then we move the point according to where the error is minimized. There are different problems with this approach like the local minima, etc. To resolve that, we use stochastic gradient descent.\n",
    "\n",
    "##### Back propagation\n",
    "Once we have determined the direction of our error, we will propagate it back to the layers and using some mathematical adjustments we will adjust the weights which will favour moving the error to the desired direction. Factors like batch size and learning rate parameter($\\alpha$) determines the speed in which it progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='preprocessing'></a>\n",
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## importing the libraries for simple linear regression.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a06301b30125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Social_Network_Ads.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "datset = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = datset.iloc[:, 2:4].values\n",
    "y = datset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='building'></a>\n",
    "### Building the model.\n",
    "Training the model using Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='result'></a>\n",
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_regions(x, y, title):\n",
    "    X_set, y_set = x, y\n",
    "    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "                 alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "    plt.xlim(X1.min(), X1.max())\n",
    "    plt.ylim(X2.min(), X2.max())\n",
    "    for i, j in enumerate(np.unique(y_set)):\n",
    "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                    c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Estimated Salary')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_regions(x_train, y_train, 'Classifier (Test set)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
